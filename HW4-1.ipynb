{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Assignment 4\n",
    "\n",
    "\n",
    "In this assignment you will use data generated from the logistic map to test multiple classifiers from the Python machine learning package *scikit-learn*. Concurrently, you will test to which extent machine learning is able to distinguish random sequences from deterministic ones. \n",
    "\n",
    "Submit all your work in two distinct Jupyter Notebooks, one answering Question 1, and one answering Question 2. \n",
    "\n",
    "Your work should be presented as a professional report, with clear description of what you are achieving. Use the formating of the chapters of [IPython Interactive Computing and Visualization Cookbook](https://github.com/ipython-books/cookbook-2nd) as examples of how to alternate code and markdown cells so that they properly complement and enhance each other. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 \n",
    "**1 point**\n",
    "\n",
    "Use the code *HW4_Question1_template* to generate an array $TrainingData=\\begin{bmatrix}M\\\\M_P      \n",
    "\\end{bmatrix}$ of shape $(3000,300)$.\n",
    "\n",
    "Set $M$ to be an array of shape $(1500,300)$, with each of its rows an (asymptotic) sequence of iterations of the logistic map, with $r=3.9$ and multiple random initial values $x_0$.\n",
    "\n",
    "Set $M_P$ to be such that its rows are each a random permutation of the corresponding rows of $M$.\n",
    "\n",
    "Create a corresponding array $TrainingTargets=\\begin{bmatrix}C_1\\\\C_2      \n",
    "\\end{bmatrix}$ where $C_1$ and $C_2$ are both arrays of shape $(1500,1)$ and all the elements of $C_1$ are equal to $1$, all the elements of $C_2$ are equal to $0$.\n",
    "\n",
    "\n",
    "Repeart the same operations to generate new arrays $TestData$ and $TestTargets$ with respectively the same structure of $TrainingData$ and $TrainingTargets$.\n",
    "\n",
    "Save the arrays $TrainingData$, $TrainingTargets$, $TestData$, $TestTargets$ in a single HDF5 file containing two groups: *TrainingArrays* and *TestingArrays*.\n",
    "\n",
    "Explain carefully in a markdown cell what is the purpose of creating these arrays and fully comment the code in the template.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time (from question 2) I had to run this file again to change something, I had to delete the file and create a new one from this code. I used the same file name so you might have to as well as it may come up with an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n",
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "\n",
    "def logistic(r, x):\n",
    "    return r * x * (1 - x) #logistic function\n",
    "\n",
    "def runlogistic(N,last): #runlogistic method function\n",
    "    iterations=5000 #variable\n",
    "    \n",
    "    \n",
    "    x=np.random.uniform(0,1,(1,N)) #Draw samples from a uniform distribution.\n",
    "    R=3.9\n",
    "    M=np.zeros((N,last)) #create array size (n,last)\n",
    "    \n",
    "    \n",
    "    for i in range(iterations): #for loop\n",
    "        x = logistic(R, x) #uses logistic function to create values for dataset.\n",
    "        \n",
    "        \n",
    "        if i>=(iterations-last):\n",
    "            M[:,i-iterations]=x #adds value to array\n",
    "         \n",
    "    \n",
    "    M_P=np.zeros((N,last)) #create array size (n,last)\n",
    "    \n",
    "    for j in range(N):\n",
    "        l_per=M[j,:]            \n",
    "        \n",
    "        l_per=np.random.permutation(l_per) #permutates the above array\n",
    "        M_P[j,:]=l_per\n",
    "        \n",
    "        \n",
    "    Data=np.concatenate((M, M_P), axis=0) #add the arrays together\n",
    "    return Data #return the function\n",
    "\n",
    "\n",
    "N=1500 #variable\n",
    "TrainingData=runlogistic(N,300) #runs function, gets array from function\n",
    "target1=np.ones(N) #array of ones size n\n",
    "target2=np.zeros(N) #array of zeros size n\n",
    "Targets=np.concatenate((target1,target2), axis=0) # adds the two arrays above\n",
    "TrainingTargets=Targets # assign to different varible\n",
    "\n",
    "\n",
    "f = h5py.File('example_files.hdf5', 'w') #\"write on the file hdf5\"\n",
    "f['TrainingArrays/TrainingData'] = TrainingData #Training data is in the file located at 'TrainingArrays/TrainingData'\n",
    "f['TrainingArrays/TrainingData'].attrs['features'] = 'logistic and permuted logistic sequences'\n",
    "f['TrainingArrays/TrainingData'].attrs['Growth Coefficient'] = '3.9'\n",
    "f['TrainingArrays/TrainingTargets']=TrainingTargets #TrainingTargets is in the file located at 'TrainingArrays/TrainingTargets'\n",
    "f.close()\n",
    "\n",
    "\n",
    "f = h5py.File('example_files.hdf5', 'r+') #reading+ the file hdf5\n",
    "\n",
    "N=1500\n",
    "TestData = runlogistic(N,300)#runs function, gets array from function\n",
    "\n",
    "target1=np.ones(N)#array of ones size n\n",
    "target2=np.zeros(N)#array of zeros size n\n",
    "Targets=np.concatenate((target1,target2), axis=0)# adds the two arrays above\n",
    "TestTargets=Targets# assign to different varible\n",
    "\n",
    "f['TestArrays/TestData'] = TestData#TestData is in the file located at 'TestArrays/TestData'\n",
    "f['TestArrays/TestTargets'] = TestTargets #TestTargets is in the file located at 'TestArrays/TestTargets'\n",
    "f.close()\n",
    "#training arrays \"features\" -> 'logistic and permuted logistic sequences'\n",
    "#training data \"Growth Coefficient\" -> 3.9\n",
    "#do the same thing for the test data\n",
    "#Don't need attributes on homework\n",
    "#HDF5 Files combine two things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above creates data to put into the file \"example_files.hdf5\". hdf5 files are very helpful to the community. It's very easy to share and use the data for any file. The printall function makes everything even easier because it tells you everything thats in the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When first looking at this file. I was so lost. Though the assignments that you had us do in class really helped me understand how to use the hdf5 files. I can now confidently extract and put information into these files. Though I had to differ from the assignment a little bit. I kept coming up with errors if my array for the secord portion wasn't a (1500,300) which didn't make sense to me. I was able to get data by changing the value."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
